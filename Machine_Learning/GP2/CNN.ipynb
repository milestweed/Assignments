{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "welsh-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-training",
   "metadata": {},
   "source": [
    "## Functions to run KFold CV on CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "eleven-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "    if hasattr(layer, 'reset_parameters'):\n",
    "        print(f'Reset trainable parameters of layer = {layer}')\n",
    "        layer.reset_parameters()\n",
    "    \n",
    "def torchKFold(net, dataset, name):    \n",
    "    # Configuration options\n",
    "    k_folds = 5\n",
    "    num_epochs = 1\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    # For fold results\n",
    "    results = {}\n",
    "\n",
    "    # Set fixed random number seed\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # Define the K-fold Cross Validator\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "    # Start print\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "        # Print\n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "\n",
    "        # Sample elements randomly from a given list of ids, no replacement.\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "        # Define data loaders for training and testing data in this fold\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "                          dataset, \n",
    "                          batch_size=10, sampler=train_subsampler)\n",
    "        testloader = torch.utils.data.DataLoader(\n",
    "                          dataset,\n",
    "                          batch_size=10, sampler=test_subsampler)\n",
    "\n",
    "        # Init the neural network\n",
    "        network = net()\n",
    "        network.apply(reset_weights)\n",
    "\n",
    "        # Initialize optimizer\n",
    "        optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "\n",
    "        # Run the training loop for defined number of epochs\n",
    "        for epoch in range(0, num_epochs):\n",
    "\n",
    "          # Print epoch\n",
    "          print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "          # Set current loss value\n",
    "          current_loss = 0.0\n",
    "\n",
    "          # Iterate over the DataLoader for training data\n",
    "          for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            # Get inputs\n",
    "            inputs, targets = data\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Perform forward pass\n",
    "            outputs = network(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_function(outputs, targets)\n",
    "\n",
    "            # Perform backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Perform optimization\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            current_loss += loss.item()\n",
    "            if i % 500 == 499:\n",
    "                print('Loss after mini-batch %5d: %.3f' %\n",
    "                      (i + 1, current_loss / 500))\n",
    "                current_loss = 0.0\n",
    "\n",
    "        # Process is complete.\n",
    "        print('Training process has finished. Saving trained model.')\n",
    "\n",
    "        # Print about testing\n",
    "        print('Starting testing')\n",
    "\n",
    "        # Saving the model\n",
    "        save_path = f'./model-{name}-fold-{fold}.pth'\n",
    "        torch.save(network.state_dict(), save_path)\n",
    "\n",
    "        # Evaluationfor this fold\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "\n",
    "          # Iterate over the test data and generate predictions\n",
    "          for i, data in enumerate(testloader, 0):\n",
    "\n",
    "            # Get inputs\n",
    "            inputs, targets = data\n",
    "\n",
    "            # Generate outputs\n",
    "            outputs = network(inputs)\n",
    "\n",
    "            # Set total and correct\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "        # Print accuracy\n",
    "        print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "        print('--------------------------------')\n",
    "        results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "        # Print fold results\n",
    "        print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "        print('--------------------------------')\n",
    "        sum = 0.0\n",
    "        for key, value in results.items():\n",
    "            print(f'Fold {key}: {value} %')\n",
    "            sum += value\n",
    "            print(f'Average: {sum/len(results.items())} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "literary-obligation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "adverse-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root = '/home/mtweed/Documents/New_College/_Misl/data/',\n",
    "                            train = True,\n",
    "                            download = False,\n",
    "                            transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "increased-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dsets.MNIST(root = '/home/mtweed/Documents/New_College/_Misl/data/',\n",
    "                            train = False,\n",
    "                            download = False,\n",
    "                            transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-reasoning",
   "metadata": {},
   "source": [
    "## CNN One\n",
    "**Build The Neural Network Class**\n",
    "\n",
    "This first Convolutional Neural Netowork has two convolutional layers with kernal_size=3, stride=1, and padding=0 which are the default values.\n",
    "\n",
    "Each convolutional layer is pooled using a max pool algorithm with kernel_size=2 and a stride equal to the length of the kernel (2).\n",
    "\n",
    "Finally, it has one fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "stable-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet1, self).__init__()\n",
    "        \n",
    "        # Convolutional Layer 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,\n",
    "                               out_channels=16,\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # Max Pool of Layer 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Convolutional Layer 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=16,\n",
    "                               out_channels=32,\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=0)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # Max Pool of Layer 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(in_features=32*5*5,\n",
    "                            out_features=10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        # Conv 1\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        # Pool layer 1\n",
    "        out = self.maxpool1(out)\n",
    "        \n",
    "        # Conv 2\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        # Pool Layer 2\n",
    "        out = self.maxpool2(out)\n",
    "        \n",
    "        # Flatten out\n",
    "        out = out.view(-1, 32*5*5)\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-drilling",
   "metadata": {},
   "source": [
    "## KFold CV on CNN One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "corresponding-testament",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=800, out_features=10, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 1.784\n",
      "Loss after mini-batch  1000: 0.622\n",
      "Loss after mini-batch  1500: 0.414\n",
      "Loss after mini-batch  2000: 0.315\n",
      "Loss after mini-batch  2500: 0.280\n",
      "Loss after mini-batch  3000: 0.260\n",
      "Loss after mini-batch  3500: 0.239\n",
      "Loss after mini-batch  4000: 0.211\n",
      "Loss after mini-batch  4500: 0.198\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 0: 94 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 94.61666666666667 %\n",
      "Average: 94.61666666666667 %\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=800, out_features=10, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 1.740\n",
      "Loss after mini-batch  1000: 0.618\n",
      "Loss after mini-batch  1500: 0.421\n",
      "Loss after mini-batch  2000: 0.353\n",
      "Loss after mini-batch  2500: 0.312\n",
      "Loss after mini-batch  3000: 0.283\n",
      "Loss after mini-batch  3500: 0.250\n",
      "Loss after mini-batch  4000: 0.248\n",
      "Loss after mini-batch  4500: 0.230\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 1: 93 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 94.61666666666667 %\n",
      "Average: 47.30833333333334 %\n",
      "Fold 1: 93.77499999999999 %\n",
      "Average: 94.19583333333333 %\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=800, out_features=10, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 1.805\n",
      "Loss after mini-batch  1000: 0.619\n",
      "Loss after mini-batch  1500: 0.402\n",
      "Loss after mini-batch  2000: 0.346\n",
      "Loss after mini-batch  2500: 0.291\n",
      "Loss after mini-batch  3000: 0.269\n",
      "Loss after mini-batch  3500: 0.247\n",
      "Loss after mini-batch  4000: 0.239\n",
      "Loss after mini-batch  4500: 0.216\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 2: 94 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 94.61666666666667 %\n",
      "Average: 31.53888888888889 %\n",
      "Fold 1: 93.77499999999999 %\n",
      "Average: 62.79722222222222 %\n",
      "Fold 2: 94.34166666666667 %\n",
      "Average: 94.24444444444445 %\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=800, out_features=10, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 1.690\n",
      "Loss after mini-batch  1000: 0.594\n",
      "Loss after mini-batch  1500: 0.410\n",
      "Loss after mini-batch  2000: 0.358\n",
      "Loss after mini-batch  2500: 0.319\n",
      "Loss after mini-batch  3000: 0.292\n",
      "Loss after mini-batch  3500: 0.245\n",
      "Loss after mini-batch  4000: 0.235\n",
      "Loss after mini-batch  4500: 0.235\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 3: 93 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 94.61666666666667 %\n",
      "Average: 23.65416666666667 %\n",
      "Fold 1: 93.77499999999999 %\n",
      "Average: 47.09791666666666 %\n",
      "Fold 2: 94.34166666666667 %\n",
      "Average: 70.68333333333334 %\n",
      "Fold 3: 93.51666666666667 %\n",
      "Average: 94.0625 %\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=800, out_features=10, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 1.733\n",
      "Loss after mini-batch  1000: 0.640\n",
      "Loss after mini-batch  1500: 0.416\n",
      "Loss after mini-batch  2000: 0.348\n",
      "Loss after mini-batch  2500: 0.309\n",
      "Loss after mini-batch  3000: 0.290\n",
      "Loss after mini-batch  3500: 0.252\n",
      "Loss after mini-batch  4000: 0.225\n",
      "Loss after mini-batch  4500: 0.226\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 4: 93 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 94.61666666666667 %\n",
      "Average: 18.923333333333336 %\n",
      "Fold 1: 93.77499999999999 %\n",
      "Average: 37.67833333333333 %\n",
      "Fold 2: 94.34166666666667 %\n",
      "Average: 56.54666666666667 %\n",
      "Fold 3: 93.51666666666667 %\n",
      "Average: 75.25 %\n",
      "Fold 4: 93.76666666666667 %\n",
      "Average: 94.00333333333333 %\n"
     ]
    }
   ],
   "source": [
    "torchKFold(NeuralNet1, train_dataset, \"one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-database",
   "metadata": {},
   "source": [
    "## CNN Two\n",
    "**Build The Neural Network Class**\n",
    "\n",
    "For this model we reduced the number of channels out to 10 on the first layer (down from 16) and 20 on the second layer (down from 32) and we changes the kernel size to 5.\n",
    "\n",
    "We also added another fully connected layer and two dropout points (one for convolution layer 2 and one for the first fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "actual-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        \n",
    "        # Convolutional Layer 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,\n",
    "                               out_channels=10,\n",
    "                               kernel_size=5,\n",
    "                               stride=1,\n",
    "                               padding=0)\n",
    "\n",
    "        # Convolutional Layer 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=10,\n",
    "                               out_channels=20,\n",
    "                               kernel_size=5,\n",
    "                               stride=1,\n",
    "                               padding=0)\n",
    "        \n",
    "        # Drop out for Conv2\n",
    "        self.dropC2 = nn.Dropout2d()\n",
    "        \n",
    "        # Fully connected layer 1\n",
    "        self.fc1 = nn.Linear(in_features=20*4*4,\n",
    "                            out_features=50)\n",
    "        \n",
    "        # Fully connected layer 2\n",
    "        self.fc2 = nn.Linear(in_features=50,\n",
    "                             out_features=10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        # Conv 1\n",
    "        out = self.conv1(x)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        #print('C1 ', out.shape)\n",
    "        \n",
    "        # Conv 2\n",
    "        out = self.conv2(out)\n",
    "        out = self.dropC2(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        #print('C2 ', out.shape)\n",
    "        \n",
    "        # Flatten out\n",
    "        out = out.view(-1, 20*4*4)\n",
    "        \n",
    "        #print('flat ', out.shape)\n",
    "        \n",
    "        # Fully Connected Layer 1\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        # Drop out FC\n",
    "        out = F.dropout(out, training=self.training)\n",
    "        \n",
    "        # Fully Connected Layer 2\n",
    "        out = self.fc2(out)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-hampton",
   "metadata": {},
   "source": [
    "## KFold CV on CNN Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "perceived-saver",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=320, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 2.219\n",
      "Loss after mini-batch  1000: 1.586\n",
      "Loss after mini-batch  1500: 1.113\n",
      "Loss after mini-batch  2000: 0.921\n",
      "Loss after mini-batch  2500: 0.813\n",
      "Loss after mini-batch  3000: 0.719\n",
      "Loss after mini-batch  3500: 0.689\n",
      "Loss after mini-batch  4000: 0.618\n",
      "Loss after mini-batch  4500: 0.591\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 0: 82 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 82.075 %\n",
      "Average: 82.075 %\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=320, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 2.230\n",
      "Loss after mini-batch  1000: 1.628\n",
      "Loss after mini-batch  1500: 1.094\n",
      "Loss after mini-batch  2000: 0.907\n",
      "Loss after mini-batch  2500: 0.789\n",
      "Loss after mini-batch  3000: 0.703\n",
      "Loss after mini-batch  3500: 0.673\n",
      "Loss after mini-batch  4000: 0.664\n",
      "Loss after mini-batch  4500: 0.584\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 1: 82 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 82.075 %\n",
      "Average: 41.0375 %\n",
      "Fold 1: 82.28333333333333 %\n",
      "Average: 82.17916666666667 %\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=320, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 2.228\n",
      "Loss after mini-batch  1000: 1.507\n",
      "Loss after mini-batch  1500: 1.032\n",
      "Loss after mini-batch  2000: 0.855\n",
      "Loss after mini-batch  2500: 0.770\n",
      "Loss after mini-batch  3000: 0.679\n",
      "Loss after mini-batch  3500: 0.608\n",
      "Loss after mini-batch  4000: 0.581\n",
      "Loss after mini-batch  4500: 0.565\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 2: 84 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 82.075 %\n",
      "Average: 27.358333333333334 %\n",
      "Fold 1: 82.28333333333333 %\n",
      "Average: 54.78611111111112 %\n",
      "Fold 2: 84.11666666666666 %\n",
      "Average: 82.825 %\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=320, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 2.246\n",
      "Loss after mini-batch  1000: 1.637\n",
      "Loss after mini-batch  1500: 1.095\n",
      "Loss after mini-batch  2000: 0.874\n",
      "Loss after mini-batch  2500: 0.779\n",
      "Loss after mini-batch  3000: 0.724\n",
      "Loss after mini-batch  3500: 0.656\n",
      "Loss after mini-batch  4000: 0.626\n",
      "Loss after mini-batch  4500: 0.553\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 3: 83 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 82.075 %\n",
      "Average: 20.51875 %\n",
      "Fold 1: 82.28333333333333 %\n",
      "Average: 41.08958333333334 %\n",
      "Fold 2: 84.11666666666666 %\n",
      "Average: 62.118750000000006 %\n",
      "Fold 3: 83.53333333333333 %\n",
      "Average: 83.00208333333333 %\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=320, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=10, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 2.211\n",
      "Loss after mini-batch  1000: 1.552\n",
      "Loss after mini-batch  1500: 1.098\n",
      "Loss after mini-batch  2000: 0.921\n",
      "Loss after mini-batch  2500: 0.802\n",
      "Loss after mini-batch  3000: 0.747\n",
      "Loss after mini-batch  3500: 0.681\n",
      "Loss after mini-batch  4000: 0.633\n",
      "Loss after mini-batch  4500: 0.601\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 4: 82 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 82.075 %\n",
      "Average: 16.415 %\n",
      "Fold 1: 82.28333333333333 %\n",
      "Average: 32.87166666666667 %\n",
      "Fold 2: 84.11666666666666 %\n",
      "Average: 49.69500000000001 %\n",
      "Fold 3: 83.53333333333333 %\n",
      "Average: 66.40166666666667 %\n",
      "Fold 4: 82.075 %\n",
      "Average: 82.81666666666666 %\n"
     ]
    }
   ],
   "source": [
    "torchKFold(NeuralNet2, train_dataset,'two')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-removal",
   "metadata": {},
   "source": [
    "## CNN Three\n",
    "**Build The Neural Network Class**\n",
    "\n",
    "Finally, we kept the structure of the first NN and doubled the output channels for both of the convolutional layer.  We also increased the kernel size to 6 for the first convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "theoretical-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet3, self).__init__()\n",
    "        \n",
    "        # Convolutional Layer 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,\n",
    "                               out_channels=32,\n",
    "                               kernel_size=6,\n",
    "                               stride=1,\n",
    "                               padding=0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # Max Pool of Layer 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Convolutional Layer 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=32,\n",
    "                               out_channels=64,\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=0)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # Max Pool of Layer 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(in_features=64*4*4,\n",
    "                            out_features=10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        # Conv 1\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        #print('C1 ', out.shape)\n",
    "        \n",
    "        # Pool layer 1\n",
    "        out = self.maxpool1(out)\n",
    "        \n",
    "        #print('P1 ', out.shape)\n",
    "        \n",
    "        # Conv 2\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        #print('C2 ', out.shape)\n",
    "        \n",
    "        # Pool Layer 2\n",
    "        out = self.maxpool2(out)\n",
    "        \n",
    "        #print('P2 ', out.shape)\n",
    "        \n",
    "        # Flatten out\n",
    "        out = out.view(-1, 64*4*4)\n",
    "        \n",
    "        #print('flat ', out.shape)\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        out = F.relu(self.fc(out))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-merchandise",
   "metadata": {},
   "source": [
    "## KFold CV on CNN Three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "inside-afghanistan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 32, kernel_size=(6, 6), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=1024, out_features=10, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 1.831\n",
      "Loss after mini-batch  1000: 1.236\n",
      "Loss after mini-batch  1500: 1.007\n",
      "Loss after mini-batch  2000: 0.932\n",
      "Loss after mini-batch  2500: 0.923\n",
      "Loss after mini-batch  3000: 0.848\n",
      "Loss after mini-batch  3500: 0.849\n",
      "Loss after mini-batch  4000: 0.863\n",
      "Loss after mini-batch  4500: 0.870\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 0: 66 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 66.24166666666666 %\n",
      "Average: 66.24166666666666 %\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 32, kernel_size=(6, 6), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=1024, out_features=10, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 1.826\n",
      "Loss after mini-batch  1000: 1.335\n",
      "Loss after mini-batch  1500: 1.194\n",
      "Loss after mini-batch  2000: 1.164\n",
      "Loss after mini-batch  2500: 1.147\n",
      "Loss after mini-batch  3000: 1.118\n",
      "Loss after mini-batch  3500: 1.063\n",
      "Loss after mini-batch  4000: 1.058\n",
      "Loss after mini-batch  4500: 1.077\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 1: 57 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 66.24166666666666 %\n",
      "Average: 33.12083333333333 %\n",
      "Fold 1: 57.31666666666667 %\n",
      "Average: 61.77916666666667 %\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 32, kernel_size=(6, 6), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=1024, out_features=10, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 1.967\n",
      "Loss after mini-batch  1000: 1.470\n",
      "Loss after mini-batch  1500: 1.186\n",
      "Loss after mini-batch  2000: 1.117\n",
      "Loss after mini-batch  2500: 1.129\n",
      "Loss after mini-batch  3000: 1.071\n",
      "Loss after mini-batch  3500: 1.057\n",
      "Loss after mini-batch  4000: 1.097\n",
      "Loss after mini-batch  4500: 1.052\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 2: 57 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 66.24166666666666 %\n",
      "Average: 22.080555555555552 %\n",
      "Fold 1: 57.31666666666667 %\n",
      "Average: 41.18611111111111 %\n",
      "Fold 2: 57.75833333333333 %\n",
      "Average: 60.43888888888889 %\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 32, kernel_size=(6, 6), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=1024, out_features=10, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 2.052\n",
      "Loss after mini-batch  1000: 1.698\n",
      "Loss after mini-batch  1500: 1.611\n",
      "Loss after mini-batch  2000: 1.581\n",
      "Loss after mini-batch  2500: 1.550\n",
      "Loss after mini-batch  3000: 1.516\n",
      "Loss after mini-batch  3500: 1.506\n",
      "Loss after mini-batch  4000: 1.533\n",
      "Loss after mini-batch  4500: 1.498\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 3: 48 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 66.24166666666666 %\n",
      "Average: 16.560416666666665 %\n",
      "Fold 1: 57.31666666666667 %\n",
      "Average: 30.889583333333334 %\n",
      "Fold 2: 57.75833333333333 %\n",
      "Average: 45.329166666666666 %\n",
      "Fold 3: 48.24166666666667 %\n",
      "Average: 57.389583333333334 %\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 32, kernel_size=(6, 6), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=1024, out_features=10, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch   500: 1.935\n",
      "Loss after mini-batch  1000: 1.372\n",
      "Loss after mini-batch  1500: 1.215\n",
      "Loss after mini-batch  2000: 1.209\n",
      "Loss after mini-batch  2500: 1.166\n",
      "Loss after mini-batch  3000: 1.115\n",
      "Loss after mini-batch  3500: 1.112\n",
      "Loss after mini-batch  4000: 1.093\n",
      "Loss after mini-batch  4500: 1.092\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 4: 57 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 66.24166666666666 %\n",
      "Average: 13.248333333333331 %\n",
      "Fold 1: 57.31666666666667 %\n",
      "Average: 24.711666666666666 %\n",
      "Fold 2: 57.75833333333333 %\n",
      "Average: 36.263333333333335 %\n",
      "Fold 3: 48.24166666666667 %\n",
      "Average: 45.91166666666667 %\n",
      "Fold 4: 57.58333333333333 %\n",
      "Average: 57.42833333333333 %\n"
     ]
    }
   ],
   "source": [
    "torchKFold(NeuralNet3, train_dataset, 'Three')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "broadband-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "elect-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('model-one-fold-4.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "derived-frequency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "stone-shopper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the best CNN on the test data is: tensor(94.8200)\n"
     ]
    }
   ],
   "source": [
    "# Calculate Accuracy         \n",
    "correct = 0\n",
    "total = 0\n",
    "# Iterate through test dataset\n",
    "for images, labels in test_loader:\n",
    "\n",
    "    test = Variable(images.view(100,1,28,28))\n",
    "    # Forward propagation\n",
    "    outputs = model(test)\n",
    "    # Get predictions from the maximum value\n",
    "    predicted = torch.max(outputs.data, 1)[1]\n",
    "\n",
    "    # Total number of labels\n",
    "    total += len(labels)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "accuracy = 100 * correct / float(total)\n",
    "\n",
    "print(\"The accuracy of the best CNN on the test data is:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
