---
title: "Assignment 1"
subtitle: "Data Quality Measurement"
author: "Miles Tweed"
date: '`r format(Sys.time(), "%d %b %Y")`'
output: pdf_document
---

## Toy Data Frame Construction

I first created some messy "survey" data in order to test my function.  The data included the respondent's name, phone number, state/territory of residence, job, and company. A number from 1-10 indicating the respondents 'positivity' and a measure from 0-1 of their "aptitude" are the quantitative variables. I used a package call charlatan to generate the data, as well as, to create missing data. The data frame named 'toydf1' is the most complete set of date while 'toydf2' and 'toydf3' have increasing amounts of missing data and introduced errors.
```{r}
#install.packages('charlatan')
library(charlatan)

# This is a list of every US state and territory to sample from for the 'state' variable
states <- c('AL', 'AK', 'AS', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE','DC','FL',
            'GA','GU','HI','ID','IL','IN','IA','KS','KY','LA','ME','MD',
            'MA','MI','MN','MS','MO','MT','NE','NV','NM','NY','NC','ND',
            'MP','OH','OK','OR','PA','PR','RI','SC','SD','TN','TX','UT',
            'VT','VA','VL','WA','WV','WI','WY')
state_list_len <- length(states)

# These vectors contain the fake data generated by charlatan
name_var <- ch_name(n = 1000)
state_var <- sample(states, 1000, replace = T)
one_ten_var <- ch_integer(n = 1000, min = 0, max = 10)
double_var <- ch_double(n = 1000, mean = 0.5, sd = 0.1)
company_var <- ch_company(n = 1000)
phone_var <- sample(c('17483028294', '19425551234','12345678902',
                         '1-942-877-8399', '1-888-837-3888'),
                       size = 1000, replace = T)
job_var <- ch_job(n = 1000)

# This data frame forms the basis that the latter dataframes are copied from and 
# contains the most complete data. The 'positivity' variable is supposed to be 
# between 0 and 1, however, the charlatan function used to generate the data will
# inevitably have values outside of this range
toydf1 <- data.frame(1:1000, name_var, phone_var, state_var, 
                     job_var, company_var, one_ten_var, double_var)
names(toydf1) <- c('id', 'name','phone', 'state', 'job', 'company', 
                   'positivity', 'aptitude')

# For toydf2, I used charlatan to generate missing data in the job and 
# phone columns and I removed four of the states from the sample (FL, PR, WV, CA)
toydf2 <- toydf1
toydf2$job <- ch_missing(toydf2$job, n = 1)
toydf2$phone <- ch_missing(toydf2$phone, n = 1)
toydf2$state[toydf2$state == 'FL'] <- 'MD'
toydf2$state[toydf2$state == 'PR'] <- 'MO'
toydf2$state[toydf2$state == 'WV'] <- 'SC'
toydf2$state[toydf2$state == 'CA'] <- 'SC'
toydf2$aptitude <- ch_double(n = 1000, mean = 0.5, sd = 0.4)

# For toydf3 I removed data from the job, and name variables.  
# I added values beyond the 0-10 range for positivity and 
# further increased the potential errors in aptitude. 
# Finally, I removed many more states/territories from the state variable. 
toydf3 <- toydf1
toydf3$job <- ch_missing(toydf3$job, n = 1)
toydf3$positivity <- one_ten_var <- ch_integer(n = 1000, min = -11, max = 18)
toydf3$name <- ch_missing(toydf3$name, n = 1)
toydf3$aptitude <- ch_double(n = 1000, mean = 0.5, sd = 0.6)
for (st in c('ME','MD','MA','MI','MN','MS','MO',
             'MT','NE','NV','NM','NY','NC','ND',
             'MP','OH','OK','OR','PA','PR','RI',
             'SC','SD','UT','VT','VA','VL','WA',
             'WV','WI','WY')){
  toydf3$state[toydf3$state == st] <- 'AL'
}

```

## Function Definition

My function is called data.score and it generates a data frame that contains the scores per variable of the metrics measured.  If a variable is not scored, the data fram will contain an NA at that position.  All scores are standardized between 0 and 1.  The scores are only measures of positive outcomes (completeness, free of errors, consistant representation, appropriate amount of data), as opposed to negative ones (missing values, errors, inconsistant representation, inappropriate amount of data).
```{r}
data.score <- function(df) {
  # First I defined the vectors that will be used to generate the data frame at the end
  cmplt_score <- vector()
  foe_apt_score <- vector()
  foe_pos_score <- vector()
  con_rep_phn_score <- vector()
  app_amt_score <- vector()
  
  # The first for loop iterates over the variables (8 for toydf1(2)(3))
  for (i in 1:length(df)) {
    
    # This block of code performs the missing value check.
    # This is the only measure performed on every variable.
    na_var_count <- sum(is.na(df[i]))
    len <- length(df[[i]])
    score <- (1 - (na_var_count/len))
    cmplt_score <- append(cmplt_score, score)
    
    # This object is used to identify the scoring process that needs to run.
    var_name <- names(df[i])
    
    # If the current variable is 'state', this generates a score representing
    # how appropriate the amount of data is for being representative of the US.
    # Only surveying one state would lead to a low score while a survey of every
    # state would lead to a high score.  In truth, this metric needs be a bit more
    # robust and also characterize the amount of data collected from each state, 
    # since the opinion of one person in Florida is hardly representative of the state
    # as a whole. 
    if ('state' == var_name){
     max_sts <- 54
     df_sts <- length(unique(df[,'state']))
      
      # The score is saved as the proportion of states surveyed out of the whole
      app_amt_score <- df_sts/max_sts
    } 
    else{  
      if (var_name == 'aptitude') {
      # The aptitude score should be between 0 and 1. 
      # Any thing else would be considered an error
      errors <- (sum(df[,'aptitude'] < 0, na_rm = T) + 
                   sum(df[,'aptitude'] > 1, na_rm = T))
      error_score <- (errors / length(df[,'aptitude']))
      
      # The score is saved as the number of error free records
      foe_apt_score <- (1 - error_score)
      } 
      else{  
        if (var_name == 'positivity') {
        # The positivity score should be between 0 and 10. 
        # Any thing else would be considered an error
        errors <- (sum(df[,'positivity'] < 0, na_rm = T) + 
                   sum(df[,'positivity'] > 10, na_rm = T))
        error_score <- (errors / length(df[,'positivity']))
        
        # The score is saved as the number of error free records
        foe_pos_score <- (1 - error_score)
        } 
        else { 
          if (var_name == 'phone') {
          # The proper phone representation, for this toy model, is an 11 digit number
          # (country code)(area code)(7 digit phone number), typical of the US, without
          # any non numeric characters (i.e. 19415551234). Anything outsideof this
          # representation will be considered inconsistant.
          phn_error = 0
            # Iterates over every record
            for (i in 1:length(df[,'phone'])) {
              
              # Changes the number to a string split into individual characters
              splt_phn <- strsplit(toString(df[i,'phone']), split = '')
              
              #This counts the violations of the formatting convention
              count = 0
              for (i in 1:length(splt_phn[[1]])) {
                count = count + sum(splt_phn[[1]][i] %in% c('.','-','x','(',')'))
              }
              count = count + sum(length(splt_phn[[1]]) != 11)
              # only one violation is rquired to flag the record as inconsistant
              if (count > 0) {phn_error = phn_error + 1}
            }
          # The score is calculated as the proportion of consistant records
          con_rep_phn_score <- 1 - (phn_error/length(df[,'phone']))
          }
        }
      }
    }
  }
  
  # The following code generates the score_card data frame
  # The score columns will first be initialized with NA values
  init_nas <- rep(NA, times = length(names(df)))
  score_card = data.frame(names(df),cmplt_score,init_nas,init_nas,init_nas)
  names(score_card) <- c('variable', 'completeness', 
                         'free_of_error', 'appropriate_amount', 
                         'consistant_rep')
  score_card[match(c('aptitude'), names(toydf1)),'free_of_error'] <- foe_apt_score
  score_card[match(c('positivity'), names(toydf1)),'free_of_error'] <- foe_pos_score
  score_card[match(c('phone'), names(toydf1)),'consistant_rep'] <- con_rep_phn_score
  score_card[match(c('state'), names(toydf1)),'appropriate_amount'] <- app_amt_score
  
  # The score card is the output of the function
  score_card
} 
```

## Testing The Function

### Testing the toydf1 set

The first test will be on the toydf1 data frame which will be the most complete collection of data. Notably, the phone variable recieves a very low score for consistancy.  This is because the charlatan function generates phone numbers in a very inconsistant manner. 
```{r}
data.score(toydf1)
```

### Testing the toydf2 set

Notably, the consistant representation score is affected by the introduction of missing data. While it should be possible to remove this effect, I feel that the property of being consistantly represented in the records constitutes the consistant representation quality metric.
```{r}
data.score(toydf2)
```

### Testing the toydf3 set
```{r}
data.score(toydf3)
```


